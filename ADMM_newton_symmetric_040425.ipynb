{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEWCpTeAg0ul"
   },
   "source": [
    "**Generate the B graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.ma.extras import average\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "# plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------Notations---------\n",
    "p = dimensions \n",
    "n_samples = number of samples\n",
    "a = vector to generate toeplitz matrix B, dimension of vector is 2p-1 and dimension of matrix B is (p x p)\n",
    "\n",
    "sigma_x = covariance matrix of X\n",
    "X ~ N(mu_x, sigma_x)\n",
    "\n",
    "Y = B^(-1).X\n",
    "sigma_y = covariance matrix of Y, sigma_y = B^(-1).X.B^(-T)\n",
    "Y ~ N(mu_y, sigma_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_mat_symmetric(a, p):\n",
    "    '''To generate a symmetric toeplitz matrix with a given vector 'a' '''\n",
    "    # Vector 'a' can only be of length p (odd length indexing from 0 to p-1 and center at 0)\n",
    "    # Initialize a zeros matrix of size nxn\n",
    "    result = np.zeros((p, p))\n",
    "\n",
    "    # Fill in the main diagonal with center element of a\n",
    "    np.fill_diagonal(result, a[0])\n",
    "\n",
    "    # Fill in sub/super-diagonals (below the main diagonal)\n",
    "    for i in range(1, p):\n",
    "        np.fill_diagonal(result[i:], -1*a[i]) # Sub-diagonals\n",
    "        np.fill_diagonal(result[:,i:], -1*a[i]) # Super-diagonals\n",
    "    return result\n",
    "\n",
    "\n",
    "def B_mat_lowertriangular(a, p):\n",
    "    '''To generate a lower triangular toeplitz matrix with a given vector 'a' '''\n",
    "    # Vector 'a' can only be of length p (odd length indexing from 0 to p-1 and center at 0)\n",
    "    # Initialize a zeros matrix of size nxn\n",
    "    result = np.zeros((p, p))\n",
    "\n",
    "    # Fill in the main diagonal with center element of a\n",
    "    np.fill_diagonal(result, a[0])\n",
    "\n",
    "    # Fill in sub/diagonals (below the main diagonal)\n",
    "    for i in range(1, p):\n",
    "        np.fill_diagonal(result[i:], -1*a[i]) # Sub-diagonals\n",
    "    return result\n",
    "\n",
    "\n",
    "def cov_x(p):\n",
    "    \"\"\" Generate the covariance matrix for x\"\"\"\n",
    "    sigma_x = np.eye(p)\n",
    "    return sigma_x\n",
    "\n",
    "\n",
    "def cov_y(sigma_x, B):\n",
    "    \"\"\" Generate covariance matrix for Y i.e. (B^(-1).X.B^(-T)) since Y=B^(-1).X\"\"\"\n",
    "    B_inv = np.linalg.solve(B, np.eye(B.shape[0]))\n",
    "    sigma_y = B_inv@sigma_x@B_inv.T\n",
    "    return sigma_y\n",
    "\n",
    "\n",
    "def generate_y(mean_y, sigma_y, n_samples):\n",
    "    \"\"\" Generate samples of Y\"\"\"\n",
    "    y_samples = multivariate_normal.rvs(mean=mean_y, cov=sigma_y, size=n_samples)\n",
    "    return y_samples\n",
    "\n",
    "def samp_cov2(y_samples):\n",
    "    n_samples = len(y_samples)\n",
    "    samp_cov_y = np.sum(np.array([np.outer(y_samples[i],y_samples[i]) for i in range(n_samples)]), axis=0)/n_samples \n",
    "    return samp_cov_y\n",
    "    \n",
    "def samp_cov(y_samples):\n",
    "    \"\"\" Generating sample covariance matrix \"\"\"\n",
    "    # n_samples = len(y_samples)\n",
    "    # samp_cov_y = np.sum(np.array([np.outer(y_samples[i],y_samples[i]) for i in range(n_samples)]), axis=0)/n_samples \n",
    "    # return samp_cov_y\n",
    "    # TODO: check if bias=True divides the sum by n_samples\n",
    "    return np.cov(y_samples, rowvar=False, bias=True)\n",
    "\n",
    "\n",
    "def soft(x, y):\n",
    "    return np.sign(x) * np.maximum(np.abs(x) - y, 0)\n",
    "\n",
    "\n",
    "def threshold(vec, threshold_value=0.002):\n",
    "    vec1 = vec.copy()\n",
    "    vec1[np.abs(vec) < threshold_value] = 0\n",
    "    return vec1\n",
    "\n",
    "\n",
    "def binarize_matrix(matrix):\n",
    "    '''Converts non-zero elements to 1 and keeps zeros as zeros.'''\n",
    "    binary_matrix = np.where(matrix != 0, 1, 0)\n",
    "    return binary_matrix\n",
    "\n",
    "\n",
    "def compute_recovery_rate_numpy(a_binary, true_a_binary):\n",
    "    joint_ones = np.sum((a_binary == 1) & (true_a_binary == 1)) # True positives + False positives\n",
    "    ones_true_a = np.sum(true_a_binary == 1) # True positives\n",
    "    if ones_true_a == 0:\n",
    "        return 0\n",
    "    return joint_ones / ones_true_a\n",
    "\n",
    "\n",
    "def create_sparse_vec_pos_def_2(dim, nonzeros, diag=20):\n",
    "    ''' Function to create sparse vector(p x 1) which can generate symmetric +ve definite toeplitz matrix'''\n",
    "    vec = np.zeros((dim,))\n",
    "    vec[0] = diag\n",
    "    nonzeros -= 1\n",
    "    # selection of indicies with the non-zero entry (random selection)\n",
    "    non_zero_indices = random.sample(range(1,dim),nonzeros)\n",
    "    for idx in non_zero_indices:\n",
    "        # Randomly assign values to non-zero entries \n",
    "        vec[idx] = random.randint(1,5)\n",
    "    return vec\n",
    "\n",
    "\n",
    "### Different functions for ADMM ###\n",
    "\n",
    "def f1(a, S, sigma_x, rho, a2, mu1, regularized = False):\n",
    "    \"\"\" Function evaluation for Newton method with regularization term based on ADMM\n",
    "       TODO: verify this Tr[S.Theta_y] - logdet(Theta_y) + rho/2*||a1 - a2 + mu1||_1\"\"\"\n",
    "    p = S.shape[0]\n",
    "    a.reshape((-1,))\n",
    "    B = B_mat_symmetric(a, p)\n",
    "    theta_x = np.linalg.solve(sigma_x, np.eye(p))\n",
    "    if regularized:\n",
    "        # Added [1:] since we don't want to regularize a0\n",
    "        reg_term = (rho/2)*np.linalg.norm(a[1:]-a2+mu1)\n",
    "    else:\n",
    "        reg_term = 0\n",
    "    return np.trace(S@B.T@theta_x@B)-np.log(np.linalg.det(B.T@theta_x@B))+reg_term \n",
    "\n",
    "\n",
    "def f2(a, lam):\n",
    "    \"\"\" Function evaluation of regularization term \"\"\"\n",
    "    return lam*np.linalg.norm(a[1:],1)\n",
    "    \n",
    "    \n",
    "def f(a, S, sigma_x):\n",
    "    a.reshape((-1,))\n",
    "    B = B_mat_symmetric(a, S.shape[0])\n",
    "    sigma_x_inv = np.linalg.solve(sigma_x, np.eye(S.shape[0]))\n",
    "    return np.trace(S@B.T@sigma_x_inv@B) - np.log(np.linalg.det(B.T@sigma_x_inv@B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_T_matrices(p, symmetric=False):\n",
    "    \"\"\"\n",
    "    Returns a list [T0, T1, …, T(p-1)]\n",
    "    for every j!=0 T[j] is a pxp matrix with jth super and subdiagonals with entries 1\n",
    "    for j=0 its an Identity matrix\n",
    "    \"\"\"\n",
    "    T_list = []\n",
    "    I = np.eye(p)\n",
    "    T_list.append(I)\n",
    "    for j in range(1, p):\n",
    "        M = np.zeros((p, p))\n",
    "        # sub‑diagonal\n",
    "        M[np.arange(j, p), np.arange(0, p-j)] = -1\n",
    "        if symmetric:\n",
    "            # super‑diagonal\n",
    "            M[np.arange(0, p-j), np.arange(j, p)] = -1\n",
    "        T_list.append(M)\n",
    "    return T_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kll(a, a_hat, sigma_x):\n",
    "    ''' Computing the KL loss for the covariance matrices of Y'''\n",
    "    p = len(a)\n",
    "    B = B_mat_symmetric(a, p)\n",
    "    B_hat = B_mat_symmetric(a_hat, p)\n",
    "    sigma_y = cov_y(sigma_x, B)\n",
    "    sigma_y_hat = cov_y(sigma_x, B_hat)\n",
    "    theta_y_hat = np.linalg.solve(sigma_y_hat, np.eye(p))\n",
    "    theta_y = np.linalg.solve(sigma_y, np.eye(p))\n",
    "    return np.trace(sigma_y@theta_y_hat) - np.log(np.linalg.det(sigma_y@theta_y_hat)) - p\n",
    "\n",
    "def rkll(a, a_hat, sigma_x):\n",
    "    ''' Computing the reverse KL loss for the covariance matrices of Y'''\n",
    "    return kll(a_hat, a, sigma_x)\n",
    "\n",
    "def rte(a, a_hat, sigma_x):\n",
    "    ''' Computing the relative trace error loss for the precision matrix'''\n",
    "    p = len(a)\n",
    "    B = B_mat_symmetric(a, p)\n",
    "    B_hat = B_mat_symmetric(a_hat, p)\n",
    "    sigma_y = cov_y(sigma_x, B)\n",
    "    sigma_y_hat = cov_y(sigma_x, B_hat)\n",
    "    theta_y_hat = np.linalg.solve(sigma_y_hat, np.eye(p))\n",
    "    theta_y = np.linalg.solve(sigma_y, np.eye(p))\n",
    "    return abs(1 - (np.trace(theta_y_hat)/np.trace(theta_y)))\n",
    "\n",
    "def norm_loss(a, a_hat, sigma_x):\n",
    "    ''' Computing the norm loss for the precision matrix'''\n",
    "    p = len(a)\n",
    "    B = B_mat_symmetric(a, p)\n",
    "    B_hat = B_mat_symmetric(a_hat, p)\n",
    "    sigma_y = cov_y(sigma_x, B)\n",
    "    sigma_y_hat = cov_y(sigma_x, B_hat)\n",
    "    theta_y_hat = np.linalg.solve(sigma_y_hat, np.eye(p))\n",
    "    theta_y = np.linalg.solve(sigma_y, np.eye(p))\n",
    "    fro = np.linalg.norm(theta_y-theta_y_hat,ord='fro')\n",
    "    spe = np.linalg.norm(theta_y-theta_y_hat,ord=2)\n",
    "    l1 = np.linalg.norm(theta_y-theta_y_hat,ord=1)\n",
    "    return fro, spe, l1\n",
    "\n",
    "def scores(a, a_hat, threshold_value):\n",
    "    ''' Computing the support recovery based scores for the precision matrix'''\n",
    "    a_thr = threshold(a_hat, threshold_value=threshold_value) # Apply the threshold\n",
    "    a_binary = binarize_matrix(a_thr)  # Change the output to a binary matrix to check for support recovery\n",
    "    true_a_binary = binarize_matrix(a)  # True Support Vector\n",
    "    cm = confusion_matrix(true_a_binary, a_binary)\n",
    "    tn,fp,fn,tp = cm[0,0], cm[0,1], cm[1,0], cm[1,1]\n",
    "    accuracy = (tn + tp)/np.sum(cm)\n",
    "    specificity = (tn)/(tn + fp) # TN/(TN+FP)\n",
    "    sensitivity = (tp)/(tp + fn) # TP/(TP+FN)\n",
    "    MCC = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "    return accuracy, specificity, sensitivity, MCC, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_f(x, S, sigma_x, rho, a2, mu1, T_list, regularized = False):\n",
    "    ''' Computing gradient for f1(x) = Tr(S B(x) T B(x)) + log(det(B(x) T B(x)))\n",
    "        both regularized and unregularized, where B is symmetric'''\n",
    "    p = S.shape[0] # Dimensions\n",
    "    # B = B_mat_symmetric(x, p) # Generating B matrix with a given x\n",
    "    B = sum(x[j]*T_list[j] for j in range(p))\n",
    "    B_inv = np.linalg.solve(B, np.eye(p))\n",
    "    theta_x = np.linalg.solve(sigma_x, np.eye(p))\n",
    "    \n",
    "    if regularized:\n",
    "        k = np.zeros_like(x)\n",
    "        k[1:] = x[1:]-a2+mu1\n",
    "    else:\n",
    "        k = np.zeros_like(x)\n",
    "    # TODO: check if np.einsum() is better here\n",
    "    gradient = np.zeros((p,))\n",
    "    for i in range(p):\n",
    "            Ti = T_list[i] \n",
    "            gradient[i] = 2*np.trace((S@B@theta_x@Ti) - (B_inv@Ti)) + (rho*k[i])\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def hessian_f(x, S, sigma_x, rho,T_list, regularized = False):\n",
    "    ''' Computing Hessian for f1(x) = Tr(S B(x) T B(x)) + log(det(B(x) T B(x)))\n",
    "        both regularized and unregularized, where B is symmetric'''\n",
    "    p = S.shape[0]\n",
    "    # B = B_mat_symmetric(x, p)\n",
    "    B = sum(x[j]*T_list[j] for j in range(p))\n",
    "    B_inv = np.linalg.solve(B, np.eye(p))  \n",
    "    # B_inv = np.linalg.solve(B, stack all Tis)  \n",
    "    theta_x = np.linalg.solve(sigma_x, np.eye(p))\n",
    "    \n",
    "    hessian = np.zeros((p,p))\n",
    "    for i in range(p):\n",
    "        Ti = T_list[i]\n",
    "        for j in range(p):\n",
    "            Tj = T_list[j]\n",
    "            hessian[i,j] = 2*(np.trace(S@Ti@theta_x@Tj) + np.trace(B_inv@Ti@B_inv@Tj))\n",
    "    if regularized:\n",
    "        reg = rho*np.eye(p)\n",
    "        reg[0,0] = 0\n",
    "        hessian+=reg\n",
    "    return hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gH(x, S, rho, a2, mu1, T_list, B, B_inv, theta_x, regularized = False):\n",
    "    p=S.shape[0]\n",
    "    # compute gradient\n",
    "    if regularized:\n",
    "        k = np.zeros_like(x)\n",
    "        k[1:] = x[1:]-a2+mu1\n",
    "    else:\n",
    "        k = np.zeros_like(x)\n",
    "    gradient = np.zeros((p,))\n",
    "    for i in range(p):\n",
    "            Ti = T_list[i] \n",
    "            gradient[i] = 2*np.trace((S@B@theta_x@Ti) - (B_inv@Ti)) + (rho*k[i])\n",
    "\n",
    "    # compute hessian\n",
    "    hessian = np.zeros((p,p))\n",
    "    for i in range(p):\n",
    "        Ti = T_list[i]\n",
    "        for j in range(p):\n",
    "            Tj = T_list[j]\n",
    "            hessian[i,j] = 2*(np.trace(S@Ti@theta_x@Tj) + np.trace(B_inv@Ti@B_inv@Tj))\n",
    "    if regularized:\n",
    "        reg = rho*np.eye(p)\n",
    "        reg[0,0] = 0\n",
    "        hessian+=reg\n",
    "\n",
    "    return gradient, hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Newtons Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_newton_step(gradient, hessian):\n",
    "    \"\"\"\n",
    "    Computes the Newton step and decrement.\n",
    "\n",
    "    Parameters:\n",
    "    gradient (np.array): Gradient vector.\n",
    "    hessian (np.array): Hessian matrix.\n",
    "\n",
    "    Returns:\n",
    "    delta_x_nt (np.array): Newton step.\n",
    "    lambd (float): Newton decrement.\n",
    "    \"\"\"\n",
    "    delta_x_nt = -np.linalg.solve(hessian, gradient)  # Newton step\n",
    "    lambd_sqr = np.dot(gradient.T, hessian@gradient)  # Newton decrement\n",
    "    return delta_x_nt, lambd_sqr\n",
    "\n",
    "def backtracking_line_search(f, gradient, x, delta_x_nt, S, sigma_x, rho, a2, mu1,\n",
    "                             regularized=False, alpha=0.01, beta=0.5):\n",
    "    \"\"\"\n",
    "    Backtracking line search to ensure sufficient decrease.\n",
    "\n",
    "    Parameters:\n",
    "    f (function): Function to minimize.\n",
    "    gradient (np.array): Gradient vector.\n",
    "    x (np.array): Current point.\n",
    "    delta_x_nt (np.array): Newton step.\n",
    "    alpha (float): Alpha parameter for backtracking.\n",
    "    beta (float): Beta parameter for backtracking.\n",
    "\n",
    "    Returns:\n",
    "    t (float): Step size.\n",
    "    \"\"\"\n",
    "    t = 1  # Start with full step size\n",
    "    p = S.shape[0]\n",
    "    x_ = x + t * delta_x_nt\n",
    "    # TODO: check if choelsky decomposition method of checking psd constraint is actually faster and reliable\n",
    "    e_val, _ = np.linalg.eig(B_mat_symmetric(x_, p))\n",
    "    i = 0\n",
    "    while not np.all(e_val>0): \n",
    "        t *= beta # Reduce step size so that x + del_x is PSD\n",
    "        x_ = x + t * delta_x_nt\n",
    "        e_val, _ = np.linalg.eig(B_mat_symmetric(x_, p))\n",
    "        i+=1\n",
    "        if(i%5==0):\n",
    "            print(f\"   PSD-loop  iter={i:2d}  t={t:.2e}  λ_min={e_val[0]:.2e}\")\n",
    "        if i>20:\n",
    "            t = 0\n",
    "            print('Backtracking line search (I) went beyond 20 iterations')\n",
    "            break\n",
    "    x_ = x + t * delta_x_nt\n",
    "    i = 0\n",
    "    while (f(x_,S,sigma_x,rho,a2,mu1,regularized=regularized)\\\n",
    "           >f(x,S,sigma_x,rho,a2,mu1,regularized=regularized)\\\n",
    "           + alpha*t*np.dot(gradient.T,delta_x_nt)):\n",
    "        t *= beta  # Reduce step size\n",
    "        x_ = x + t * delta_x_nt\n",
    "        # if(i%5==0):\n",
    "            # print(f\"   Armijo    t={t:.2e}\")\n",
    "        if (i>20) or (t==0):\n",
    "            t = 0\n",
    "            print('Backtracking line search (II) went beyond 20 iterations')\n",
    "            break\n",
    "    return t\n",
    "\n",
    "\n",
    "def projection_Rp(x):\n",
    "    y = np.maximum(x, np.zeros_like(x))\n",
    "    return y\n",
    "\n",
    "\n",
    "def newton_method(f, x0, S, sigma_x, rho, a2, mu1, T_list, epsilon=1e-6, alpha=0.01, beta=0.5,\n",
    "                  regularized=False, backtracking=False, projection=False):\n",
    "    \"\"\"\n",
    "    Implements Newton's method for optimization.\n",
    "\n",
    "    Parameters:\n",
    "    f (function): Function to minimize.\n",
    "    grad_f (function): Gradient function.\n",
    "    hessian_f (function): Hessian function.\n",
    "    x0 (np.array): Initial point.\n",
    "    epsilon (float): Stopping criterion for Newton decrement.\n",
    "    alpha (float): Alpha parameter for backtracking.\n",
    "    beta (float): Beta parameter for backtracking.\n",
    "\n",
    "    Returns:\n",
    "    x (np.array): Optimized point.\n",
    "    \"\"\"\n",
    "    x = x0\n",
    "    i = 0\n",
    "    p=S.shape[0]\n",
    "    B = sum(x[j]*T_list[j] for j in range(p))\n",
    "    B_inv = np.linalg.solve(B, np.eye(p))\n",
    "    theta_x = np.linalg.solve(sigma_x, np.eye(p))\n",
    "\n",
    "    while True:\n",
    "        gradient,hessian = compute_gH(x, S, rho, a2, mu1, T_list, B, B_inv,theta_x, regularized=regularized)\n",
    "        \n",
    "        # Compute Newton step and decrement\n",
    "        delta_x_nt, lambd_sqr = compute_newton_step(gradient, hessian)\n",
    "        \n",
    "        # Stopping criterion\n",
    "        if lambd_sqr / 2 <= epsilon:\n",
    "            print('Stopping Criteria Met at iteration ', i)\n",
    "            # print(lambd_sqr, delta_x_nt)\n",
    "            # print(i)\n",
    "            break\n",
    "\n",
    "        # Backtracking line search\n",
    "        if backtracking:\n",
    "            # print(\"line search\")\n",
    "            t = backtracking_line_search(f, gradient, x, delta_x_nt, S, sigma_x, rho, a2, mu1,\n",
    "                                         regularized=regularized, alpha=alpha, beta=beta)\n",
    "            print(f\"line search step size t = {t:.2e}\")\n",
    "        else:\n",
    "            t = 1\n",
    "        # print(t)\n",
    "            \n",
    "        # Update x\n",
    "        x_old = x.copy()\n",
    "        x = x + t*delta_x_nt\n",
    "\n",
    "        # Project x on R+\n",
    "        if projection:\n",
    "            x = projection_Rp(x)\n",
    "        \n",
    "        if i%10==0:\n",
    "            # print(lambd_sqr, delta_x_nt)\n",
    "            # print(i)\n",
    "            print('Newton algorithm finished 10 iterations, lambda_sqr: ', lambd_sqr)\n",
    "            \n",
    "        if (i>=20):\n",
    "            print('Newton algorithm finished 50 iterations')\n",
    "            break\n",
    "        \n",
    "        if (i>1) and (np.linalg.norm(x_old-x)<=epsilon):\n",
    "            print('not much change in x observed')\n",
    "            print(i)\n",
    "            break\n",
    "        i+=1\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo Version of ADMM (Since f1 is not in closed form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADMM_newton(f, iterations, rho, lambda_param, S, sigma_x, a, T_list, epsilon=1e-6,\n",
    "                alpha=0.5, beta=0.7, regularized=False, backtracking=True,\n",
    "                projection=True, perturbed=False, tol=1e-4):\n",
    "    p = S.shape[0]\n",
    "    e0 = np.zeros((p,))\n",
    "    e0[0] = 1\n",
    "    a1 = e0.copy()\n",
    "    a2 = np.zeros((p-1,))\n",
    "    mu1 = np.zeros((p-1,))\n",
    "    if perturbed:\n",
    "        a1 = a + 0.1*np.random.randn(p)\n",
    "        a2 = a[1:] + 0.1*np.random.randn(p-1)\n",
    "    if regularized:\n",
    "        print('Regularized - ADMM + Newton')\n",
    "        for i in range(iterations):       \n",
    "            print('='*50, \"iteration \", i, '='*50)\n",
    "            a2_old = a2.copy()\n",
    "            a1_ = newton_method(f, a1, S, sigma_x, rho, a2, mu1, T_list, epsilon=epsilon,\n",
    "                                alpha=alpha, beta=beta, regularized=regularized,\n",
    "                                backtracking=backtracking, projection=projection)\n",
    "            print(\"Completed Newton Iteration\")\n",
    "            a2_ = soft(a1_[1:]+mu1,lambda_param/rho)\n",
    "            mu1_ = mu1 + (a1_[1:]-a2_)\n",
    "            a1, a2, mu1 = a1_, a2_, mu1_\n",
    "\n",
    "            primal_res = np.linalg.norm(a1[1:] - a2)\n",
    "            dual_res = np.linalg.norm(rho * (a2 - a2_old))\n",
    "            if(i%10==0):\n",
    "                print(f\"Primal: {primal_res}, Dual: {dual_res}, tol: {tol}\")\n",
    "            if primal_res <= tol and dual_res <= tol:\n",
    "                break\n",
    "\n",
    "    else:\n",
    "        print('Unregularized - Newton')\n",
    "        for i in range(iterations):       \n",
    "            print('='*50, \"iteration \", i, '='*50)\n",
    "            a1_ = newton_method(f, a1, S, sigma_x, rho, a2, mu1, T_list, epsilon=epsilon,\n",
    "                                alpha=alpha, beta=beta, regularized=regularized,\n",
    "                                backtracking=backtracking, projection=projection)\n",
    "            a1 = a1_\n",
    "    return a1, a2, mu1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulations - Symmetric Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization for multiple simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 50  # Dimensions of the square toeplitz matrix\n",
    "d = 15   # Sparsity of the (px1) vextor => no of non zero entries in (2p x 1) = 2d-1\n",
    "const = 0.1  # multiplicative factor for number of samples\n",
    "n_samples = int(const*(d*d*np.log(p))) # number of samples for the problem setup\n",
    "num_rep = 1  # number of repetitions of the algorithm\n",
    "\n",
    "rho = 2\n",
    "lambda_param = 0.01\n",
    "iterations = 50\n",
    "T_list = make_T_matrices(p)\n",
    "regularize = True\n",
    "backtrack = True\n",
    "project = True\n",
    "perturb = False\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Matrix =  50 Sparsity =  15\n",
      "__________________________________________________ Run =  0 __________________________________________________\n",
      "Regularized - ADMM + Newton\n",
      "================================================== iteration  0 ==================================================\n",
      "line search step size t = 1.00e+00\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  999955.2513964183\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 9.73e-14\n",
      "not much change in x observed\n",
      "9\n",
      "Completed Newton Iteration\n",
      "Primal: 0.0006165238495452961, Dual: 0.0, tol: 0.0001\n",
      "================================================== iteration  1 ==================================================\n",
      "line search step size t = 1.00e+00\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  99.58268131413493\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 8.02e-15\n",
      "not much change in x observed\n",
      "7\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  2 ==================================================\n",
      "line search step size t = 1.00e+00\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.0179757348017235\n",
      "line search step size t = 7.00e-01\n",
      "line search step size t = 5.61e-15\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  3 ==================================================\n",
      "line search step size t = 1.00e+00\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.006041630212472743\n",
      "Stopping Criteria Met at iteration  1\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  4 ==================================================\n",
      "line search step size t = 4.92e-12\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.00733635910609263\n",
      "line search step size t = 6.81e-14\n",
      "line search step size t = 8.02e-15\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  5 ==================================================\n",
      "line search step size t = 3.45e-12\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.007405003750074692\n",
      "line search step size t = 9.73e-14\n",
      "line search step size t = 3.34e-14\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  6 ==================================================\n",
      "line search step size t = 1.39e-13\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.0075127291956715025\n",
      "line search step size t = 1.39e-13\n",
      "line search step size t = 1.39e-13\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  7 ==================================================\n",
      "line search step size t = 1.39e-13\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.007581964241369655\n",
      "line search step size t = 1.39e-13\n",
      "line search step size t = 1.39e-13\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  8 ==================================================\n",
      "line search step size t = 1.39e-13\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.007676279828170823\n",
      "line search step size t = 1.39e-13\n",
      "line search step size t = 1.39e-13\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  9 ==================================================\n",
      "line search step size t = 1.39e-13\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.007801741078141508\n",
      "line search step size t = 1.39e-13\n",
      "line search step size t = 1.39e-13\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  10 ==================================================\n",
      "line search step size t = 1.39e-13\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.007927419920713398\n",
      "line search step size t = 1.39e-13\n",
      "line search step size t = 1.39e-13\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "Primal: 0.0010137388124353542, Dual: 0.0008593903550080506, tol: 0.0001\n",
      "================================================== iteration  11 ==================================================\n",
      "line search step size t = 1.39e-13\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008029996321361758\n",
      "line search step size t = 1.39e-13\n",
      "line search step size t = 1.39e-13\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  12 ==================================================\n",
      "line search step size t = 1.39e-13\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008118767223776403\n",
      "line search step size t = 1.39e-13\n",
      "line search step size t = 1.39e-13\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  13 ==================================================\n",
      "line search step size t = 4.05e-13\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008188482936618623\n",
      "line search step size t = 1.39e-13\n",
      "line search step size t = 9.73e-14\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  14 ==================================================\n",
      "line search step size t = 1.39e-13\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008235395534354102\n",
      "line search step size t = 1.39e-13\n",
      "line search step size t = 1.39e-13\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  15 ==================================================\n",
      "line search step size t = 1.39e-13\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008258912073629722\n",
      "line search step size t = 1.15e-14\n",
      "line search step size t = 1.92e-15\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  16 ==================================================\n",
      "line search step size t = 3.81e-17\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008290688238189915\n",
      "line search step size t = 3.81e-17\n",
      "line search step size t = 3.81e-17\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  17 ==================================================\n",
      "line search step size t = 3.81e-17\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008328919686253202\n",
      "line search step size t = 3.81e-17\n",
      "line search step size t = 3.81e-17\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  18 ==================================================\n",
      "line search step size t = 8.54e-11\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008374454829416227\n",
      "line search step size t = 1.22e-10\n",
      "line search step size t = 4.92e-12\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  19 ==================================================\n",
      "line search step size t = 1.74e-10\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008423131437165107\n",
      "line search step size t = 4.18e-11\n",
      "line search step size t = 8.54e-11\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  20 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008474949509433461\n",
      "line search step size t = 7.26e-10\n",
      "line search step size t = 4.05e-13\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "Primal: 0.0003388260567550101, Dual: 0.0008704155288269179, tol: 0.0001\n",
      "================================================== iteration  21 ==================================================\n",
      "line search step size t = 1.98e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008503802189811374\n",
      "line search step size t = 3.56e-10\n",
      "line search step size t = 1.44e-11\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  22 ==================================================\n",
      "line search step size t = 1.98e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008507953458834592\n",
      "line search step size t = 5.98e-11\n",
      "line search step size t = 3.56e-10\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  23 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008492258203202391\n",
      "line search step size t = 1.48e-09\n",
      "line search step size t = 5.98e-11\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  24 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.00848892344092822\n",
      "line search step size t = 8.54e-11\n",
      "line search step size t = 2.49e-10\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  25 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008489058829852323\n",
      "line search step size t = 5.08e-10\n",
      "line search step size t = 3.56e-10\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  26 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.00848919197050272\n",
      "line search step size t = 2.12e-09\n",
      "line search step size t = 8.54e-11\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  27 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008489322619110926\n",
      "line search step size t = 6.17e-09\n",
      "line search step size t = 8.27e-13\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  28 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008489450526975357\n",
      "line search step size t = 3.02e-09\n",
      "line search step size t = 2.49e-10\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  29 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.0084895756654919\n",
      "line search step size t = 3.02e-09\n",
      "line search step size t = 3.02e-09\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  30 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.00848969867789058\n",
      "line search step size t = 6.17e-09\n",
      "line search step size t = 3.02e-09\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "Primal: 5.104755776191023e-18, Dual: 0.0008385533113847098, tol: 0.0001\n",
      "================================================== iteration  31 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008489819315539061\n",
      "line search step size t = 1.26e-08\n",
      "line search step size t = 4.32e-09\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  32 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008489937761059633\n",
      "line search step size t = 2.12e-09\n",
      "line search step size t = 2.12e-09\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  33 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008490054157136367\n",
      "line search step size t = 6.17e-09\n",
      "line search step size t = 5.08e-10\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  34 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.00849016860026622\n",
      "line search step size t = 6.17e-09\n",
      "line search step size t = 4.05e-13\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  35 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008490281145649276\n",
      "line search step size t = 7.26e-10\n",
      "line search step size t = 6.17e-09\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  36 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008490391827576351\n",
      "line search step size t = 2.49e-10\n",
      "line search step size t = 6.17e-09\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  37 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008490500636409866\n",
      "line search step size t = 1.26e-08\n",
      "line search step size t = 1.48e-09\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  38 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008490607598035924\n",
      "line search step size t = 3.02e-09\n",
      "line search step size t = 1.48e-09\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  39 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008490712737788855\n",
      "line search step size t = 6.17e-09\n",
      "line search step size t = 1.22e-10\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  40 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.00849081608087661\n",
      "line search step size t = 8.81e-09\n",
      "line search step size t = 1.80e-08\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "Primal: 1.7376855623716135e-18, Dual: 0.0008333526409337175, tol: 0.0001\n",
      "================================================== iteration  41 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008490917652210751\n",
      "line search step size t = 1.26e-08\n",
      "line search step size t = 4.32e-09\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  42 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008491017475997922\n",
      "line search step size t = 3.56e-10\n",
      "line search step size t = 3.56e-10\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  43 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008491115576296055\n",
      "line search step size t = 1.26e-08\n",
      "line search step size t = 7.26e-10\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  44 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008491211977080634\n",
      "line search step size t = 3.02e-09\n",
      "line search step size t = 7.26e-10\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  45 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008491306701636586\n",
      "line search step size t = 1.04e-09\n",
      "line search step size t = 1.04e-09\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  46 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008491399773140581\n",
      "line search step size t = 3.02e-09\n",
      "line search step size t = 3.56e-10\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  47 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008491491207888125\n",
      "line search step size t = 3.02e-09\n",
      "line search step size t = 4.32e-09\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  48 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008491581014759353\n",
      "line search step size t = 4.32e-09\n",
      "line search step size t = 4.32e-09\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  49 ==================================================\n",
      "line search step size t = 1.38e-02\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.008491669169992258\n",
      "line search step size t = 6.17e-09\n",
      "line search step size t = 7.26e-10\n",
      "not much change in x observed\n",
      "2\n",
      "Completed Newton Iteration\n",
      "Total time taken for a run =  55.221856355667114\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "print('Dimensions of Matrix = ', p, 'Sparsity = ', d)\n",
    "for rep in range(num_rep):\n",
    "    a = create_sparse_vec_pos_def_2(p, d, diag= d*10)\n",
    "    B0 = B_mat_symmetric(a, p)\n",
    "    B0_inv = np.linalg.inv(B0)\n",
    "    sigma_x = cov_x(p)\n",
    "    sigma_y = cov_y(sigma_x,B0)\n",
    "    y_samp = generate_y(np.zeros((p,)), sigma_y, n_samples)\n",
    "    S = samp_cov(y_samp)\n",
    "    \n",
    "    total_t1 = time()\n",
    "    print('_'*50, 'Run = ', rep, '_'*50)\n",
    "    a1, a2, mu1 = ADMM_newton(f1, iterations, rho, lambda_param, S, sigma_x, a, T_list, epsilon=1e-4,\n",
    "                              alpha=0.1, beta=0.7, regularized=regularize, backtracking=backtrack,\n",
    "                              projection=project, perturbed=perturb)\n",
    "    total_t2 = time()\n",
    "    print('Total time taken for a run = ', total_t2 - total_t1)\n",
    "    \n",
    "    run_data = {'p': p, 'd':d, 'const':const, 'num_samples':n_samples, 'lambda':lambda_param, 'rho': rho,\n",
    "                'iterations': iterations, 'a': a, 'samp_y':y_samp, 'f_reg':regularize, 'f_back':backtrack,\n",
    "                'f_proj':project, 'f_perturb':perturb, 'a1':a1, 'a2':a2, 'mu1':mu1}\n",
    "    data[rep] = run_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "6\n",
      "7\n",
      "16\n",
      "17\n",
      "21\n",
      "24\n",
      "28\n",
      "31\n",
      "40\n",
      "43\n",
      "45\n",
      "47\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data[0]['a'])):\n",
    "     if data[0]['a'][i]!=0:\n",
    "          print(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "6\n",
      "7\n",
      "13\n",
      "15\n",
      "16\n",
      "19\n",
      "22\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "pp=threshold(data[0]['a1'])\n",
    "for i in range(len(data[0]['a'])):\n",
    "     if pp[i]!=0:\n",
    "          print(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(data[0].keys())\n",
    "best_thr = []\n",
    "best_rate = []\n",
    "best_acc = []\n",
    "best_f1 = []\n",
    "best_cm = []\n",
    "\n",
    "kll_const = []\n",
    "rkll_const = []\n",
    "rte_const = []\n",
    "norm_const = []\n",
    "scores_const = []\n",
    "\n",
    "threshold_range = 0.01*np.arange(101)\n",
    "for rep in range(num_rep):\n",
    "    a = data[rep][keys[7]]\n",
    "    a1 = data[rep][keys[-3]]\n",
    "    true_a_binary = binarize_matrix(a)\n",
    "    thr_rate = []\n",
    "    thr_cm = []\n",
    "    thr_acc = []\n",
    "    thr_f1 = []\n",
    "    for thr in threshold_range:  \n",
    "        a_thr = threshold(a1, threshold_value=thr) # Apply the threshold\n",
    "        a_binary = binarize_matrix(a_thr)  # Change the output to a binary matrix to check for support recovery\n",
    "        rate = compute_recovery_rate_numpy(a_binary, true_a_binary)  # Computing recovery rate\n",
    "        cm = confusion_matrix(true_a_binary, a_binary)\n",
    "        accuracy = (cm[0,0] + cm[1,1])/np.sum(cm)\n",
    "\n",
    "        thr_rate += [rate]\n",
    "        thr_cm += [cm]\n",
    "        thr_acc += [accuracy]\n",
    "        thr_f1 += [f1_score(true_a_binary, a_binary)]\n",
    "    idx = np.argmax(np.array(thr_acc))\n",
    "    best_thr += [threshold_range[idx]]\n",
    "    best_rate += [thr_rate[idx]]\n",
    "    best_acc += [thr_acc[idx]]\n",
    "    best_f1 += [thr_f1[idx]]\n",
    "    best_cm += [thr_cm[idx]]\n",
    "    a_thr = threshold(a1, threshold_value=threshold_range[idx]) # Apply the threshold\n",
    "    a_binary = binarize_matrix(a_thr)  # Change the output to a binary matrix to check for support recovery\n",
    "    \n",
    "    kll_const += [kll(a, a_thr, sigma_x)]\n",
    "    rkll_const += [rkll(a, a_thr, sigma_x)]\n",
    "    rte_const += [rte(a, a_thr, sigma_x)]\n",
    "    norm_const += [norm_loss(a, a_thr, sigma_x)]\n",
    "    scores_const += [scores(a, a1, threshold_value=threshold_range[idx])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fro_norm_const = [norm_const[i][0] for i in range(num_rep)]\n",
    "spec_norm_const = [norm_const[i][1] for i in range(num_rep)]\n",
    "l1_norm_const = [norm_const[i][2] for i in range(num_rep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8,\n",
       " 0.5,\n",
       " 0.3333333333333333,\n",
       " 0.6953924909712725,\n",
       " 0.6429225376276406,\n",
       " 0.01380183659505263]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[average(best_acc), average(best_f1), average(best_rate), average(kll_const), average(rkll_const), average(rte_const)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best lambda, rho for different p – [25, 50, 75, 100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SolverArgs:\n",
    "    def __init__(self, p=50, d=15, const=15, rho=1, lambda_param=0.01, iterations=50,\n",
    "                 regularize=True, backtrack=True, project=True, perturb=False, num_rep=50, n_samples=None):\n",
    "        self.p = p\n",
    "        self.d = d\n",
    "        self.const = const\n",
    "        self.rho = rho\n",
    "        self.lambda_param = lambda_param\n",
    "        self.iterations = iterations\n",
    "        self.regularize = regularize\n",
    "        self.backtrack = backtrack\n",
    "        self.project = project\n",
    "        self.perturb = perturb\n",
    "        self.num_rep = num_rep\n",
    "        self.n_samples = n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(self, args: SolverArgs):\n",
    "        self.args = args\n",
    "\n",
    "    def solve(self,epsilon=1e-4,alpha=0.1,beta=0.7,):\n",
    "        p = self.args.p\n",
    "        d = self.args.d\n",
    "        const = self.args.const\n",
    "        rho = self.args.rho\n",
    "        lambda_param = self.args.lambda_param\n",
    "        iterations = self.args.iterations\n",
    "        regularize = self.args.regularize\n",
    "        backtrack = self.args.backtrack\n",
    "        project = self.args.project\n",
    "        perturb = self.args.perturb\n",
    "        num_rep = self.args.num_rep\n",
    "        n_samples = self.args.n_samples\n",
    "\n",
    "        if n_samples is None:\n",
    "            n_samples = int(const * (d * d * np.log(p))) \n",
    "        print(\"Number of samples N:\", n_samples)\n",
    "        data = {}\n",
    "        T_list=make_T_matrices(p)\n",
    "\n",
    "        print('Dimensions of Matrix = ', p, 'Sparsity = ', d)\n",
    "        for rep in range(num_rep):\n",
    "            a = create_sparse_vec_pos_def_2(p, d, diag=d * 10)\n",
    "            B0 = B_mat_symmetric(a, p)\n",
    "            # B0_inv = np.linalg.inv(B0)\n",
    "            sigma_x = cov_x(p)\n",
    "            sigma_y = cov_y(sigma_x, B0)\n",
    "            y_samp = generate_y(np.zeros((p,)), sigma_y, n_samples)\n",
    "            S = samp_cov(y_samp)\n",
    "\n",
    "            total_t1 = time()\n",
    "            print('_' * 50, 'Run = ', rep, '_' * 50)\n",
    "            a1, a2, mu1 = ADMM_newton(\n",
    "                f1,\n",
    "                iterations,\n",
    "                rho,\n",
    "                lambda_param,\n",
    "                S,\n",
    "                sigma_x,\n",
    "                a,\n",
    "                T_list,\n",
    "                epsilon=epsilon,\n",
    "                alpha=alpha,\n",
    "                beta=beta,\n",
    "                regularized=regularize,\n",
    "                backtracking=backtrack,\n",
    "                projection=project,\n",
    "                perturbed=perturb\n",
    "            )\n",
    "            total_t2 = time()\n",
    "            print('Total time taken for a run = ', total_t2 - total_t1)\n",
    "\n",
    "            run_data = {\n",
    "                'p': p,\n",
    "                'd': d,\n",
    "                'const': const,\n",
    "                'num_samples': n_samples,\n",
    "                'lambda': lambda_param,\n",
    "                'rho': rho,\n",
    "                'iterations': iterations,\n",
    "                'a': a,\n",
    "                'samp_y': y_samp,\n",
    "                'f_reg': regularize,\n",
    "                'f_back': backtrack,\n",
    "                'f_proj': project,\n",
    "                'f_perturb': perturb,\n",
    "                'a1': a1,\n",
    "                'a2': a2,\n",
    "                'mu1': mu1,\n",
    "                'sigma_x': sigma_x\n",
    "            }\n",
    "            data[rep] = run_data\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def evaluate(self, data):\n",
    "        num_rep = self.args.num_rep\n",
    "        keys = list(data[0].keys())\n",
    "        threshold_range = 0.01 * np.arange(101)\n",
    "\n",
    "        best_thr = []\n",
    "        best_rate = []\n",
    "        best_acc = []\n",
    "        best_f1 = []\n",
    "        best_cm = []\n",
    "\n",
    "        kll_const = []\n",
    "        rkll_const = []\n",
    "        rte_const = []\n",
    "        norm_const = []\n",
    "        scores_const = []\n",
    "\n",
    "        for rep in range(num_rep):\n",
    "            a = data[rep][keys[7]]\n",
    "            a1 = data[rep][keys[-4]]\n",
    "            sigma_x = data[rep][keys[-1]]\n",
    "            true_a_binary = binarize_matrix(a)\n",
    "            thr_rate = []\n",
    "            thr_cm = []\n",
    "            thr_acc = []\n",
    "            thr_f1 = []\n",
    "\n",
    "            for thr in threshold_range:\n",
    "                a_thr = threshold(a1, threshold_value=thr)\n",
    "                a_binary = binarize_matrix(a_thr)\n",
    "                rate = compute_recovery_rate_numpy(a_binary, true_a_binary)\n",
    "                cm = confusion_matrix(true_a_binary, a_binary)\n",
    "                accuracy = (cm[0, 0] + cm[1, 1]) / np.sum(cm)\n",
    "\n",
    "                thr_rate.append(rate)\n",
    "                thr_cm.append(cm)\n",
    "                thr_acc.append(accuracy)\n",
    "                thr_f1.append(f1_score(true_a_binary, a_binary))\n",
    "\n",
    "            idx = np.argmax(np.array(thr_acc))\n",
    "            best_thr.append(threshold_range[idx])\n",
    "            best_rate.append(thr_rate[idx])\n",
    "            best_acc.append(thr_acc[idx])\n",
    "            best_f1.append(thr_f1[idx])\n",
    "            best_cm.append(thr_cm[idx])\n",
    "\n",
    "            a_thr = threshold(a1, threshold_value=threshold_range[idx])\n",
    "            a_binary = binarize_matrix(a_thr)\n",
    "\n",
    "            kll_const.append(kll(a, a_thr, sigma_x))\n",
    "            rkll_const.append(rkll(a, a_thr, sigma_x))\n",
    "            rte_const.append(rte(a, a_thr, sigma_x))\n",
    "            norm_const.append(norm_loss(a, a_thr, sigma_x))\n",
    "            scores_const.append(scores(a, a1, threshold_value=threshold_range[idx]))\n",
    "\n",
    "        metrics = {\n",
    "            'avg_acc': average(best_acc),\n",
    "            'avg_f1': average(best_f1),\n",
    "            'avg_rate': average(best_rate),\n",
    "            'avg_kll': average(kll_const),\n",
    "            'avg_rkll': average(rkll_const),\n",
    "            'avg_rte': average(rte_const),\n",
    "            'avg_fro': average([n[0] for n in norm_const]),\n",
    "            'avg_spec': average([n[1] for n in norm_const]),\n",
    "            'avg_l1': average([n[2] for n in norm_const])\n",
    "        }\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples N: 19428\n",
      "Dimensions of Matrix =  75 Sparsity =  15\n",
      "__________________________________________________ Run =  0 __________________________________________________\n",
      "Regularized - ADMM + Newton\n",
      "================================================== iteration  0 ==================================================\n",
      "line search step size t = 1.00e+00\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  3374847.5340872686\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 2.41e-12\n",
      "not much change in x observed\n",
      "9\n",
      "Completed Newton Iteration\n",
      "Primal: 0.010644163900215671, Dual: 0.0, tol: 0.0001\n",
      "================================================== iteration  1 ==================================================\n",
      "line search step size t = 1.00e+00\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  336.07829471391693\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.99e-13\n",
      "not much change in x observed\n",
      "7\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  2 ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rohit\\anaconda3\\Lib\\site-packages\\numpy\\linalg\\linalg.py:2139: RuntimeWarning: overflow encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line search step size t = 1.00e+00\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.055959012336548666\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.05603127444497226\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "line search step size t = 1.00e+00\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.05603127444497226\n",
      "Newton algorithm finished 50 iterations\n",
      "Completed Newton Iteration\n",
      "================================================== iteration  3 ==================================================\n",
      "line search step size t = 7.00e-01\n",
      "Newton algorithm finished 10 iterations, lambda_sqr:  0.32912477613750557\n",
      "line search step size t = 1.68e-01\n",
      "   PSD-loop  iter= 5  t=1.68e-01  λ_min=8.48e+00\n",
      "line search step size t = 5.76e-02\n",
      "   PSD-loop  iter= 5  t=1.68e-01  λ_min=-4.71e+01\n",
      "line search step size t = 1.14e-03\n",
      "   PSD-loop  iter= 5  t=1.68e-01  λ_min=-4.82e+01\n",
      "line search step size t = 2.25e-05\n",
      "   PSD-loop  iter= 5  t=1.68e-01  λ_min=-4.83e+01\n",
      "line search step size t = 5.41e-06\n",
      "   PSD-loop  iter= 5  t=1.68e-01  λ_min=-4.83e+01\n",
      "line search step size t = 1.86e-06\n",
      "   PSD-loop  iter= 5  t=1.68e-01  λ_min=-4.83e+01\n",
      "line search step size t = 3.12e-07\n",
      "   PSD-loop  iter= 5  t=1.68e-01  λ_min=-4.83e+01\n",
      "line search step size t = 5.24e-08\n",
      "not much change in x observed\n",
      "8\n",
      "Completed Newton Iteration\n",
      "Total time taken for a run =  39.545814990997314\n"
     ]
    }
   ],
   "source": [
    "defaultArgs = SolverArgs(p=75, num_rep=1, const= 20, d=15)\n",
    "defaultSolver = Solver(defaultArgs)\n",
    "data = defaultSolver.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "11\n",
      "13\n",
      "26\n",
      "30\n",
      "38\n",
      "44\n",
      "48\n",
      "53\n",
      "56\n",
      "61\n",
      "68\n",
      "70\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data[0]['a'])):\n",
    "     if data[0]['a'][i]!=0:\n",
    "          print(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pp=threshold(data[0]['a1'])\n",
    "for i in range(len(data[0]['a'])):\n",
    "     if pp[i]!=0:\n",
    "          print(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avg_acc': 0.8133333333333334,\n",
       " 'avg_f1': 0.125,\n",
       " 'avg_rate': 0.06666666666666667,\n",
       " 'avg_kll': 10.061323899781684,\n",
       " 'avg_rkll': 15.200797237433875,\n",
       " 'avg_rte': 0.43021471746660755,\n",
       " 'avg_fro': 88556.38829361374,\n",
       " 'avg_spec': 16106.584251621196,\n",
       " 'avg_l1': 24506.635334499893}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaultSolver.evaluate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = [25, 50, 75, 100]\n",
    "lambda_grid = [0.01, 0.05, 0.1, 0.2]\n",
    "rho_grid = [0.5, 1.0, 2.0]\n",
    "\n",
    "results = []\n",
    "\n",
    "for p in p_values:\n",
    "    best_loss = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "    for lamb, rho in itertools.product(lambda_grid, rho_grid):\n",
    "        args = SolverArgs(p=p, lambda_param=lamb, rho=rho, num_rep=1, n_samples=115)\n",
    "        solver = Solver(args)\n",
    "        data = solver.solve()\n",
    "        metrics = solver.evaluate(data)\n",
    "\n",
    "        result_row = {\n",
    "            'p': p,\n",
    "            'lambda': lamb,\n",
    "            'rho': rho,\n",
    "            **metrics\n",
    "        }\n",
    "        results.append(result_row)\n",
    "\n",
    "        if metrics['avg_kll'] < best_loss:\n",
    "            best_loss = metrics['avg_kll']\n",
    "            best_params = result_row\n",
    "\n",
    "    print(f\"Best for p={p}:\", best_params)\n",
    "\n",
    "# Save to CSV\n",
    "with open('grid_search_results.csv', mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=results[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(\"Results saved to 'grid_search_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results from the \n",
    "\n",
    "grid_results=[\n",
    "    {'p': 25, 'lambda': 0.01, 'rho': 0.5, 'avg_acc': 0.6599999999999999, 'avg_f1': 0.7228260869565217, 'avg_rate': 0.7666666666666666, 'avg_kll': 0.28834798256315786, 'avg_rkll': 0.24037572404236762, 'avg_rte': 0.010571042214066462, 'avg_fro': 14059.059954780245, 'avg_spec': 8117.548555305448, 'avg_l1': 10781.864332611367},\n",
    "    {'p': 50, 'lambda': 0.01, 'rho': 0.5, 'avg_acc': 0.85, 'avg_f1': 0.6933333333333334, 'avg_rate': 0.5666666666666667, 'avg_kll': 0.39462903909416625, 'avg_rkll': 0.3780700074665795, 'avg_rte': 0.02980228052349293, 'avg_fro': 18557.711485302334, 'avg_spec': 6417.824002896113, 'avg_l1': 11958.24297119836},\n",
    "    {'p': 75, 'lambda': 0.01, 'rho': 0.5, 'avg_acc': 0.9199999999999999, 'avg_f1': 0.7616191904047978, 'avg_rate': 0.6666666666666667, 'avg_kll': 0.25576180655628633, 'avg_rkll': 0.253997162116967, 'avg_rte': 0.005032227051359417, 'avg_fro': 15428.327977473476, 'avg_spec': 4211.341980301306, 'avg_l1': 8680.062740632407},\n",
    "    {'p': 100, 'lambda': 0.01, 'rho': 0.5, 'avg_acc': 0.92, 'avg_f1': 0.6747181964573269, 'avg_rate': 0.5666666666666667, 'avg_kll': 0.25180667412481483, 'avg_rkll': 0.24872118039807134, 'avg_rte': 0.00969192314341527, 'avg_fro': 15987.099300046606, 'avg_spec': 3365.7288107375443, 'avg_l1': 7326.956286608768}\n",
    "]\n",
    "\n",
    "p_values = [entry['p'] for entry in grid_results]\n",
    "avg_acc = [entry['avg_acc'] for entry in grid_results]\n",
    "avg_f1 = [entry['avg_f1'] for entry in grid_results]\n",
    "avg_rate = [entry['avg_rate'] for entry in grid_results]\n",
    "avg_kll = [entry['avg_kll'] for entry in grid_results]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(p_values, avg_acc, marker='o', label='avg_acc')\n",
    "plt.plot(p_values, avg_f1, marker='s', label='avg_f1')\n",
    "plt.plot(p_values, avg_rate, marker='^', label='avg_rate')\n",
    "plt.plot(p_values, avg_kll, marker='x', label='avg_kll')\n",
    "\n",
    "plt.xlabel('p (dimensions)')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Metrics vs Dimensions')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(grid_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity vs F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = [25, 50, 75, 100 ]\n",
    "d_list = [0.2, 0.4, 0.6, 0.8]\n",
    "lambda_val = 0.2\n",
    "rho_val = 0.1\n",
    "\n",
    "f1_results = {p: [] for p in p_list}\n",
    "metrics_list = {p: [] for p in p_list}\n",
    "\n",
    "for p in p_list:\n",
    "    for d in d_list:\n",
    "        args = SolverArgs(p=p, d=int(d*p), lambda_param=lambda_val, rho=rho_val, num_rep=2)\n",
    "        solver = Solver(args)\n",
    "        data = solver.solve()\n",
    "        metrics = solver.evaluate(data)\n",
    "        metrics_list[p].append(metrics)\n",
    "        f1_results[p].append(metrics['avg_f1'])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "for p in p_list:\n",
    "    plt.plot(d_list, f1_results[p], marker='o', label=f'p={p}')\n",
    "\n",
    "plt.xlabel('Sparsity (d)')\n",
    "plt.ylabel('Average F1 Score')\n",
    "plt.title('F1 Score vs Sparsity')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = [25, 50, 75, 100 ]\n",
    "d_list = [0.2, 0.4, 0.6, 0.8]\n",
    "sparsity_metrics = {25: [{'avg_acc': 0.84,\n",
    "   'avg_f1': 0.33333333333333337,\n",
    "   'avg_rate': 0.2,\n",
    "   'avg_kll': 1.0529756809702295,\n",
    "   'avg_rkll': 1.00702370890256,\n",
    "   'avg_rte': 0.07460000071462808,\n",
    "   'avg_fro': 3369.3685358777766,\n",
    "   'avg_spec': 1286.702401355396,\n",
    "   'avg_l1': 1904.561518694909},\n",
    "  {'avg_acc': 0.8999999999999999,\n",
    "   'avg_f1': 0.8486842105263157,\n",
    "   'avg_rate': 0.75,\n",
    "   'avg_kll': 0.5338732031481239,\n",
    "   'avg_rkll': 0.4468946836158363,\n",
    "   'avg_rte': 0.03733322017973961,\n",
    "   'avg_fro': 8496.435019246226,\n",
    "   'avg_spec': 4078.0587717504623,\n",
    "   'avg_l1': 6883.429269260107},\n",
    "  {'avg_acc': 0.9,\n",
    "   'avg_f1': 0.9125615763546798,\n",
    "   'avg_rate': 0.8666666666666667,\n",
    "   'avg_kll': 0.4719114912206077,\n",
    "   'avg_rkll': 0.3862548576717497,\n",
    "   'avg_rte': 0.03632771230451648,\n",
    "   'avg_fro': 17906.665143765968,\n",
    "   'avg_spec': 9987.140142796354,\n",
    "   'avg_l1': 14731.903700850697},\n",
    "  {'avg_acc': 0.8,\n",
    "   'avg_f1': 0.888888888888889,\n",
    "   'avg_rate': 1.0,\n",
    "   'avg_kll': 0.35935204520121466,\n",
    "   'avg_rkll': 0.27765433488975155,\n",
    "   'avg_rte': 0.026490739354071702,\n",
    "   'avg_fro': 26298.59003201731,\n",
    "   'avg_spec': 17852.059879052955,\n",
    "   'avg_l1': 23815.44598789834}],\n",
    " 50: [{'avg_acc': 0.94,\n",
    "   'avg_f1': 0.849624060150376,\n",
    "   'avg_rate': 0.8500000000000001,\n",
    "   'avg_kll': 1.2510045231720284,\n",
    "   'avg_rkll': 1.1375310561003822,\n",
    "   'avg_rte': 0.04146771391881243,\n",
    "   'avg_fro': 14536.555443014597,\n",
    "   'avg_spec': 4994.162926013361,\n",
    "   'avg_l1': 7755.348548595499},\n",
    "  {'avg_acc': 0.9299999999999999,\n",
    "   'avg_f1': 0.9039039039039038,\n",
    "   'avg_rate': 0.825,\n",
    "   'avg_kll': 0.5489098523366032,\n",
    "   'avg_rkll': 0.49414523592503556,\n",
    "   'avg_rte': 0.020336340068476955,\n",
    "   'avg_fro': 38139.20092953505,\n",
    "   'avg_spec': 17488.886348052867,\n",
    "   'avg_l1': 25376.78678795389},\n",
    "  {'avg_acc': 0.8799999999999999,\n",
    "   'avg_f1': 0.8854489164086687,\n",
    "   'avg_rate': 0.8,\n",
    "   'avg_kll': 0.45048465636688206,\n",
    "   'avg_rkll': 0.35432468602853007,\n",
    "   'avg_rte': 0.015834264085352046,\n",
    "   'avg_fro': 68646.87003640598,\n",
    "   'avg_spec': 42956.981967048014,\n",
    "   'avg_l1': 58389.37348620994},\n",
    "  {'avg_acc': 0.8,\n",
    "   'avg_f1': 0.888888888888889,\n",
    "   'avg_rate': 1.0,\n",
    "   'avg_kll': 0.30125866386172717,\n",
    "   'avg_rkll': 0.23479494800925238,\n",
    "   'avg_rte': 0.01064837713347544,\n",
    "   'avg_fro': 98657.53816855024,\n",
    "   'avg_spec': 70542.84162575958,\n",
    "   'avg_l1': 83555.5667784399}],\n",
    " 75: [{'avg_acc': 0.8266666666666667,\n",
    "   'avg_f1': 0.3125,\n",
    "   'avg_rate': 0.23333333333333334,\n",
    "   'avg_kll': 0.6924020278208189,\n",
    "   'avg_rkll': 0.6506780543877326,\n",
    "   'avg_rte': 0.01641496222353378,\n",
    "   'avg_fro': 25043.91244947046,\n",
    "   'avg_spec': 9013.495645199,\n",
    "   'avg_l1': 14222.368865444594},\n",
    "  {'avg_acc': 0.9133333333333333,\n",
    "   'avg_f1': 0.8776223776223775,\n",
    "   'avg_rate': 0.7833333333333333,\n",
    "   'avg_kll': 0.6878461242358682,\n",
    "   'avg_rkll': 0.5792023704491598,\n",
    "   'avg_rte': 0.017004769070711134,\n",
    "   'avg_fro': 90684.2025768556,\n",
    "   'avg_spec': 44430.72874636037,\n",
    "   'avg_l1': 64407.684438089724},\n",
    "  {'avg_acc': 0.8,\n",
    "   'avg_f1': 0.8228777177676222,\n",
    "   'avg_rate': 0.7777777777777777,\n",
    "   'avg_kll': 0.4182433695435748,\n",
    "   'avg_rkll': 0.3281114274557524,\n",
    "   'avg_rte': 0.009875246466152177,\n",
    "   'avg_fro': 147874.24686668307,\n",
    "   'avg_spec': 91978.58165048677,\n",
    "   'avg_l1': 124458.24315427814},\n",
    "  {'avg_acc': 0.8,\n",
    "   'avg_f1': 0.888888888888889,\n",
    "   'avg_rate': 1.0,\n",
    "   'avg_kll': 0.3967229029107884,\n",
    "   'avg_rkll': 0.2877093832410722,\n",
    "   'avg_rte': 0.008772898484739278,\n",
    "   'avg_fro': 240226.06071886263,\n",
    "   'avg_spec': 179635.58615109482,\n",
    "   'avg_l1': 205708.61006300652}],\n",
    " 100: [{'avg_acc': 0.905,\n",
    "   'avg_f1': 0.7298387096774194,\n",
    "   'avg_rate': 0.65,\n",
    "   'avg_kll': 1.129968314190485,\n",
    "   'avg_rkll': 1.0340312490496615,\n",
    "   'avg_rte': 0.02141936705046882,\n",
    "   'avg_fro': 55118.73125915954,\n",
    "   'avg_spec': 18880.351661171764,\n",
    "   'avg_l1': 28715.48422370662},\n",
    "  {'avg_acc': 0.9299999999999999,\n",
    "   'avg_f1': 0.9124497991967871,\n",
    "   'avg_rate': 0.9,\n",
    "   'avg_kll': 0.558838037590121,\n",
    "   'avg_rkll': 0.47168461203549583,\n",
    "   'avg_rte': 0.010423304478329343,\n",
    "   'avg_fro': 145273.73392863804,\n",
    "   'avg_spec': 73787.03468056445,\n",
    "   'avg_l1': 103888.62141929411},\n",
    "  {'avg_acc': 0.835,\n",
    "   'avg_f1': 0.8460471567267683,\n",
    "   'avg_rate': 0.7583333333333333,\n",
    "   'avg_kll': 0.4952250880787261,\n",
    "   'avg_rkll': 0.3768964219970883,\n",
    "   'avg_rte': 0.008359847206080295,\n",
    "   'avg_fro': 281972.9328906633,\n",
    "   'avg_spec': 179563.75601413613,\n",
    "   'avg_l1': 220145.40615935004},\n",
    "  {'avg_acc': 0.8,\n",
    "   'avg_f1': 0.888888888888889,\n",
    "   'avg_rate': 1.0,\n",
    "   'avg_kll': 0.4079200738752391,\n",
    "   'avg_rkll': 0.2975385342158958,\n",
    "   'avg_rte': 0.006868991570384508,\n",
    "   'avg_fro': 435704.4719963898,\n",
    "   'avg_spec': 319529.38321895606,\n",
    "   'avg_l1': 372844.8972469337}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_list = [1 - d for d in d_list]  # 1 - sparsity = density\n",
    "\n",
    "# sparsity_metrics dictionary should be loaded here\n",
    "\n",
    "# Initialize containers\n",
    "metrics = ['avg_acc', 'avg_f1', 'avg_rate', 'avg_kll']\n",
    "data_by_metric = {metric: {p: [] for p in p_list} for metric in metrics}\n",
    "\n",
    "# Fill the data\n",
    "for p in p_list:\n",
    "    for metric in metrics:\n",
    "        values = [sparsity_metrics[p][i][metric] for i in range(len(d_list))]\n",
    "        data_by_metric[metric][p] = values\n",
    "\n",
    "# Plot each metric separately\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for p in p_list:\n",
    "        plt.plot(density_list, data_by_metric[metric][p], marker='o', label=f'p={p}')\n",
    "    plt.xlabel('Density (1 - Sparsity)')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f'{metric} vs Density')\n",
    "    plt.grid(True)\n",
    "    plt.legend(title='Dimensions (p)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for p in p_list:\n",
    "    for i, density in enumerate(density_list):\n",
    "        record = {\n",
    "            'p': p,\n",
    "            'density': density,\n",
    "            'avg_acc': sparsity_metrics[p][i]['avg_acc'],\n",
    "            'avg_f1': sparsity_metrics[p][i]['avg_f1'],\n",
    "            'avg_rate': sparsity_metrics[p][i]['avg_rate'],\n",
    "            'avg_kll': sparsity_metrics[p][i]['avg_kll'],\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "# Create a DataFrame\n",
    "sparsity_df = pd.DataFrame(records)\n",
    "\n",
    "sparsity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tau vs F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = [75]\n",
    "tau = [0.1, 1, 5, 10, 25, 30, 40]\n",
    "d_fixed = 15\n",
    "lambda_val = 0.1\n",
    "rho_val = 0.1\n",
    "\n",
    "f1_results_ratio = {p: [] for p in p_list}\n",
    "metrics_list = {p: [] for p in p_list}\n",
    "\n",
    "for p in p_list:\n",
    "    for t in tau:\n",
    "        args = SolverArgs(p=p, d=d_fixed, const=t, lambda_param=lambda_val, rho=rho_val, num_rep=1)\n",
    "        solver = Solver(args)\n",
    "        data = solver.solve()\n",
    "        metrics = solver.evaluate(data)\n",
    "        metrics_list[p].append(metrics)\n",
    "        f1_results_ratio[p].append(metrics['avg_f1'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for p in p_list:\n",
    "    plt.plot(tau, f1_results_ratio[p], marker='o', label=f'p={p}')\n",
    "\n",
    "plt.xlabel(r\"$\\tau = N/(d^2 \\log p)$\")\n",
    "plt.ylabel('Average F1 Score')\n",
    "plt.title(r'F1 Score vs $\\tau$')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in metrics_list[100]:\n",
    "    print(x['avg_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_results_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = [0.1, 1, 5, 10, 25, 30, 40]\n",
    "p_list = [25, 50]\n",
    "sparsity_res = {25: [{'avg_acc': 0.776,\n",
    "   'avg_f1': 0.6862180629827689,\n",
    "   'avg_rate': 0.64,\n",
    "   'avg_kll': 0.32075245970498223,\n",
    "   'avg_rkll': 0.29221772495036297,\n",
    "   'avg_rte': 0.037881507511287583,\n",
    "   'avg_fro': 7315.561270709147,\n",
    "   'avg_spec': 3217.7231776224244,\n",
    "   'avg_l1': 5589.952663168258},\n",
    "  {'avg_acc': 0.876,\n",
    "   'avg_f1': 0.8087547299621602,\n",
    "   'avg_rate': 0.69,\n",
    "   'avg_kll': 0.1995468663400352,\n",
    "   'avg_rkll': 0.1938221190488953,\n",
    "   'avg_rte': 0.03355925479886487,\n",
    "   'avg_fro': 5880.659043865171,\n",
    "   'avg_spec': 2493.5131865868943,\n",
    "   'avg_l1': 4391.171950824877},\n",
    "  {'avg_acc': 0.8640000000000001,\n",
    "   'avg_f1': 0.7875952135240061,\n",
    "   'avg_rate': 0.67,\n",
    "   'avg_kll': 0.19863717474184278,\n",
    "   'avg_rkll': 0.19079123201234188,\n",
    "   'avg_rte': 0.03157514778707007,\n",
    "   'avg_fro': 5907.123700543233,\n",
    "   'avg_spec': 2763.7644303159846,\n",
    "   'avg_l1': 4545.118262898282},\n",
    "  {'avg_acc': 0.8600000000000001,\n",
    "   'avg_f1': 0.7842296918767506,\n",
    "   'avg_rate': 0.7,\n",
    "   'avg_kll': 0.20454114233157838,\n",
    "   'avg_rkll': 0.20041238024275998,\n",
    "   'avg_rte': 0.03530674621826495,\n",
    "   'avg_fro': 6019.083910734467,\n",
    "   'avg_spec': 2706.9439029205723,\n",
    "   'avg_l1': 4437.473957998895},\n",
    "  {'avg_acc': 0.852,\n",
    "   'avg_f1': 0.756495877703308,\n",
    "   'avg_rate': 0.63,\n",
    "   'avg_kll': 0.20921014822078626,\n",
    "   'avg_rkll': 0.20237656893857903,\n",
    "   'avg_rte': 0.031214674159102472,\n",
    "   'avg_fro': 6092.930578611602,\n",
    "   'avg_spec': 2661.935520275839,\n",
    "   'avg_l1': 4803.98200833042},\n",
    "  {'avg_acc': 0.908,\n",
    "   'avg_f1': 0.8677760577915377,\n",
    "   'avg_rate': 0.7699999999999999,\n",
    "   'avg_kll': 0.19129500153906492,\n",
    "   'avg_rkll': 0.18466497810698462,\n",
    "   'avg_rte': 0.03566724867116098,\n",
    "   'avg_fro': 5715.307439332556,\n",
    "   'avg_spec': 2469.9343893618743,\n",
    "   'avg_l1': 4244.8613397388635}],\n",
    "50: [{'avg_acc': 0.78,\n",
    "   'avg_f1': 0.56,\n",
    "   'avg_rate': 0.4666666666666667,\n",
    "   'avg_kll': 0.6200521664766683,\n",
    "   'avg_rkll': 0.5536236618648545,\n",
    "   'avg_rte': 0.007283350823179879,\n",
    "   'avg_fro': 22713.130606109054,\n",
    "   'avg_spec': 9257.041820343085,\n",
    "   'avg_l1': 13177.672653895686},\n",
    "  {'avg_acc': 0.92,\n",
    "   'avg_f1': 0.8666666666666667,\n",
    "   'avg_rate': 0.8666666666666667,\n",
    "   'avg_kll': 0.4705812389505226,\n",
    "   'avg_rkll': 0.446964731165977,\n",
    "   'avg_rte': 0.02169433107391716,\n",
    "   'avg_fro': 20716.16133367291,\n",
    "   'avg_spec': 8318.918487855484,\n",
    "   'avg_l1': 11522.862185665126},\n",
    "  {'avg_acc': 1.0,\n",
    "   'avg_f1': 1.0,\n",
    "   'avg_rate': 1.0,\n",
    "   'avg_kll': 0.7976771384613244,\n",
    "   'avg_rkll': 0.7495273140577794,\n",
    "   'avg_rte': 0.02922977117717973,\n",
    "   'avg_fro': 26871.722417476358,\n",
    "   'avg_spec': 10451.710785920117,\n",
    "   'avg_l1': 15249.217384916557},\n",
    "  {'avg_acc': 0.96,\n",
    "   'avg_f1': 0.9333333333333333,\n",
    "   'avg_rate': 0.9333333333333333,\n",
    "   'avg_kll': 0.8826370352138895,\n",
    "   'avg_rkll': 0.7930233277324774,\n",
    "   'avg_rte': 0.03597123412908876,\n",
    "   'avg_fro': 27049.07793792896,\n",
    "   'avg_spec': 10875.932557439635,\n",
    "   'avg_l1': 17049.58745419558},\n",
    "  {'avg_acc': 0.98,\n",
    "   'avg_f1': 0.9655172413793104,\n",
    "   'avg_rate': 0.9333333333333333,\n",
    "   'avg_kll': 0.5789453966178328,\n",
    "   'avg_rkll': 0.5474320359200959,\n",
    "   'avg_rte': 0.023121888153981418,\n",
    "   'avg_fro': 22900.602260273758,\n",
    "   'avg_spec': 8652.533406674294,\n",
    "   'avg_l1': 13798.121398497651},\n",
    "  {'avg_acc': 0.94,\n",
    "   'avg_f1': 0.888888888888889,\n",
    "   'avg_rate': 0.8,\n",
    "   'avg_kll': 0.6416226584498119,\n",
    "   'avg_rkll': 0.6054830762242318,\n",
    "   'avg_rte': 0.02268897592919572,\n",
    "   'avg_fro': 24159.56408691691,\n",
    "   'avg_spec': 9463.873614222399,\n",
    "   'avg_l1': 13856.179434700278},\n",
    "  {'avg_acc': 0.94,\n",
    "   'avg_f1': 0.888888888888889,\n",
    "   'avg_rate': 0.8,\n",
    "   'avg_kll': 0.5639035418756464,\n",
    "   'avg_rkll': 0.5294221138734088,\n",
    "   'avg_rte': 0.01934196321541992,\n",
    "   'avg_fro': 22568.231573632962,\n",
    "   'avg_spec': 9172.401101151596,\n",
    "   'avg_l1': 12848.834439632374}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = {p: [sparsity_res[p][i]['avg_f1'] for i in range(len(tau))] for p in p_list}\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "for p in p_list:\n",
    "    plt.plot(tau, f1_scores[p], marker='o', label=f'p={p}')\n",
    "\n",
    "plt.xlabel('tau')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs Tau')\n",
    "plt.grid(True)\n",
    "plt.legend(title='Dimensions (p)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
